#[IEEE VR](http://ieeevr.org/2018/program/papers.html?tdsourcetag=s_pcqq_aiomsg#papers1)
##[2019](http://ieeevr.org/2019/program/papers.html)
###[Motion parallax for 360◦ RGBD video](http://webdiis.unizar.es/~aserrano/projects/VR-6dof)(源码暂未公布)
<img src="https://i.loli.net/2019/03/19/5c9049bb12fb8.png" alt="1.png" title="1.png" />
disocclusion(遮挡图像的去除)
一种在虚拟现实头显为360°视频添加视差和实时回放的方法
背景：
现有的视频回放不能响应用户头部的平移运动，可能会给用户带来模拟器病的困扰
给定360°视频以及它对应的深度，简单的基于图像的渲染方法使用深度生成3d网格，可以相应用户头部平移。然而这种方法有看得见的扭曲以及使网格不连续
解决方案：
从输入的视频获得深度图(由现有的360缝合算法或现成的深度学习算法提供)
将给定的初始深度图改进为更干净的和自然的轮廓
依赖三层场景表示(一个前景层和两个静态背景层)
输入的视频+深度作为前景层
一个背景层表示遮挡物
另一个背景层表示遮挡物后面的背景
从第一个背景层的多帧传播信息处理不一致性，再修复第二个背景层
贡献：
为现有的360°视频提供了6自由度的观看体验(不需要新的捕捉和硬件要求)

###[MegaParallax: Casual 360° Panoramas with Motion Parallax](https://ieeexplore.ieee.org/abstract/document/8651483)
<img src="https://i.loli.net/2019/03/19/5c9054295040f.png" alt="2.png" title="2.png" />
binocular disparity(双目视差，左右眼看到的画面不同)
motion parallax(运动视差，视点改变时看到的画面不同)
背景：
用户可以用手机捕获360°全景图
全景图缺少运动视差(在不同的视点不会提供不同的画面)
研究由头部平移运动引起的运动视差是十分重要的
三维立体全景图提供的左右眼全景图是静态缝合的所以也缺少运动视差
带贴图的三维几何重建方法能提供运动视差，但是有看得见的重建噪点
解决方案：
基于单个相机的多视角全景图表示方式(用相机转360°)
不需要依靠不可靠的场景几何重建
是一种基于图像渲染的方法
贡献：
是第一个让普通消费者捕捉到带双目视差和运动视差的实时高质量360°全景图的方法

###Deep Learning-Based Approach For Automatic VR Image Upright Adjustment
背景:
相机朝向不是直的，获得的VR图像没有垂直对齐(在VR头显中图像倾斜)
解决方案：
基于深度学习的自动校正VR图像的方法
贡献：
返回校正后的视图

###Dense 3D Scene Reconstruction from Multiple Spherical Images for 3-DoF+ VR Applications
背景：
解决方案：
基于多个球状图像的室内场景3维几何重建
探索大的光流替代算法获得相应的点
使用交叉验证和几何限制检测和移除关于形变和遮挡的不好的匹配点
贡献：
根据参考画面生成稠密的深度图
提供3个自由度+的沉浸式体验

###Real-time panoramic depth maps from omni-directional stereo images for 6 DoF videos in virtual reality
一种使用CNN从全方位立体图(ODS images)获得6自由度全景视频的方法
解决方案:
用cnn实时地从ODS图生成一些深度图，这些深度图允许全景图像重投影因此能给VR中的观察者提供6自由度的体验
贡献:
提出了新的边缘权重误差函数以及新的关于全景图像拼接的误差度量

###Exploration of Large Omnidirectional Images in Immersive Environments
背景:
导航对在沉浸式环境中探索数据是一个主要挑战，特别是在大型全向球形图中。
贡献：
提出了一个自动缩放的方法允许使用者在不同焦点的物理空间的安全范围内用远程传输进行导航
该方法结合了物理导航和虚拟传输
使用缩放镜头评估了我们的系统和其它不同的传输转换
目标视图会从缩放透镜中完全扩张直到将使用者包围

###The Effect of Camera Height, Actor Behavior, and Viewer Position on the User Experience of 360° Videos
背景:
360°视频能够用头显来获得沉浸式的体验，然而观看体验是如何被360°视频的基本属性影响还没被弄明白，例如视频到底记录了多高，是否有人靠近相机
解决方案:
进行了一个24人参与的研究
研究内容：
观看体验是否被下列属性影响：
1.相机高度
2.出现在视频中的人的接近和行为
3.观看者站或坐的位置
结论:
观看者自己的高度对首选相机的高度和体验几乎没有影响
对于站和坐而言最优的相机高度大概位于150厘米
某些情况下，相机太矮或者人离相机很近会对体验有负面影响
贡献:
能够更好地理解和设计沉浸式360°体验

###Live Stereoscopic 3D Image With Constant Capture Direction of 360 Cameras for High-Quality Visual Telepresence
背景：
为了捕捉遥远的3d画面，系统要使用传统的附在机器人脑袋上的3d相机
然而相机旋转时生成的低质量图的延迟和运动模糊容易造成VR病
解决方案：
一种叫作TwinCam的方法
使用两个360°相机，保持它们的距离为标准瞳孔间距，并保持它们在世界坐标系下的镜头方向不变即使它们绕头部的轴线旋转并沿着眼睛的位置移动
这种方法能抑制图像缓冲因为每个相机在固定捕捉方向时都能捕捉全方向图
贡献：
介绍了我们相机系统的设计和它在视觉远程呈现中的潜力
我们的相机机制能减少运动模糊和VR病

###Efficient Hybrid Projection For Encoding 360 VR Videos
背景：
过去5年，市场上卖了成吨的360VR相机
360VR视频无所不在，然而数字工业的360VR视频的标准化依然引起热议
尽管ERP被广泛用于虚拟现实视频的投影和打包布局，但它在极轴处有严重的投影失真
解决方案：
新的使用混合圆柱投影的编码和存储360VR视频的格式
贡献：
能够生成平衡的像素扭曲，最小化结果投影的拉伸比例

##[2018](http://ieeevr.org/2018/program/papers.html)
###[Parallax360: Stereoscopic 360 Scene Representation for Head-Motion Parallax](https://ieeexplore.ieee.org/abstract/document/8260916)
<img src="https://i.loli.net/2019/03/19/5c90f22cc34b5.png" alt="1.png" title="1.png" />
<img src="https://i.loli.net/2019/03/19/5c90f5888cdfc.png" alt="2.png" title="2.png" />
方法：
一种新颖的360°场景表示方法来将真实场景转化为立体带头部运动视差的三维虚拟现实内容
这种基于图像的场景表示能够有效合成6自由度的新画面
在一下两个方面用到了运动场：
1.视差运动场携带隐含深度信息并且它能从多个横向偏移的辅助视点被估计出来
2.成对的运动场能够实现实时的基于流的混合，从而通过最小化重影和画面转换的噪点改进结果的视觉逼真度
贡献：
开发了一个系统：
1.它能用带有相机的机械臂捕捉真实场景
2.处理记录的数据并将场景实时渲染到头显上(大于40HZ)
这是第一个在观看真实360°场景支持头部运动视差的方法

##[The Effect of Transition Type in Multi-View 360° Media](https://ieeexplore.ieee.org/abstract/document/8260946)
<img src="https://i.loli.net/2019/03/19/5c90fc600a91d.png" alt="3.png" title="3.png" />
<img src="https://i.loli.net/2019/03/19/5c90fc5e647b8.png" alt="4.png" title="4.png" />
<img src="https://i.loli.net/2019/03/19/5c90fc61149a4.png" alt="5.png" title="5.png" />
背景：
360°图像和视频成为了沉浸显示的极受欢迎的形式
许多体验都是用单个相机视点
越来越多的体验用的是多个相机位置
当用户从一个相机位置到另一个相机位置时需要视觉效果
贡献：
调研了沉浸式MV360M(multi-view 360◦media)体验中的平移类型的效果(31个参与者戴头显，体验四个静态的场景，三个由多个360°图像组成，一个由重建3d模型组成)
调研了以下三种平移方式：
1.teleport
2.线性移动穿过场景中的3d模型
3.使用莫比乌斯变换的基于图像的转换
度量标准：
1.空间感知
2.用户的移动轮廓
3.转换偏好
4.穿过空间的主观感受

##[Generating VR Live Videos with Tripod Panoramic Rig](https://ieeexplore.ieee.org/abstract/document/8448283)
<img src="https://i.loli.net/2019/03/19/5c91085051f6a.png" alt="6.png" title="6.png" />
<img src="https://i.loli.net/2019/03/19/5c9108504e811.png" alt="7.png" title="7.png" />
背景：
将真实生活的内容转化为VR需要复杂的计算，现有的技术不能合成高质量的360°三维VR内容也不能实时合成
解决方法：
端到端的系统
能够用三角全景支架记录场景和实时广播360°立体全景视频(>30fps)
基于图像渲染

##[Detection Thresholds for Rotation and Translation Gains in 360° Video-based Telepresence System](https://ieeexplore.ieee.org/abstract/document/8314105)
<img src="https://i.loli.net/2019/03/19/5c910a94b3397.png" alt="8.png" title="8.png" />
背景：
远程传输系统能够克服现实世界的距离限制，因为它使人们可以远程访问和交互
现在的远程传输系统通常缺少自然的方法来支持遥远环境(remote environments REs)的交互和探索
单个捕捉RE的网络相机只提供有限的空间存在的幻象
现在的远程传输系统中的移动设备的移动控制受限于简单的交互设备
让用户在本地环境(local environment LE)控制遥远环境的机器平台运动是面临的主要挑战之一
解决方案：
重定向行走(redirected walking (RDW))是解决这个问题的合适方法
贡献：
进行了两个实验：
多少人可以在感觉不到遥远环境虚拟路径的重定向，这与他们在本地环境的实际行走路径是不同的
1.参与者在本地环境进行直线平移，并且被映射到远程的360°视频中的直线平移，参与者评估远程的平移感知比真实的物理场景中的平移是更快还是更慢(分析了本地和远程平移的区别)
2.参与者在本地环境进行旋转，并且被映射到远程的360°视频中的旋转，参与者评估远程的旋转感知比真实的物理场景中的旋转是更快还是更慢(分析了本地和远程旋转的区别)
结论：
当虚拟平移向下缩放5.8%到向上缩放9.7%以及虚拟旋转慢12.3%或快9.2%时参与者不能分辨本地的物理运动和远程环境360°视频的虚拟运动

##[Gaze-aware streaming solutions for the next generation of mobile VR experiences](https://ieeexplore.ieee.org/abstract/document/8269373)