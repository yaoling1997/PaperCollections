###[Deep 360 Pilot Learning a Deep Agent for Piloting through 360° Sports Videos](https://ieeexplore.ieee.org/abstract/document/8099636)
<img src="https://i.loli.net/2019/03/22/5c9449d94be2f.png" alt="8.png" title="8.png" />
<img src="https://i.loli.net/2019/03/22/5c9449d959383.png" alt="9.png" title="9.png" />
[源码、数据集和视频演示](http://aliensunmin.github.io/project/360video/)
背景：
看360°运动视频需要观察者连续选择视角，通过一系列的鼠标点击或头部运动
解决方案：
叫作deep 360 pilot的方法
自动帮用户选择合适的视角的代理人
每一帧，代理人观察全景图，结合之前帧的视角得出下一个最合适的视角并帮助观看者调整画面，使用户不需要动鼠标和头部自动获得最佳画面内容体验
视角转换尽量平滑
捕获视频中有趣的运动
运动视频的前景物体是观看者感兴趣的，所以用[最先进的物体探测器(Faster r-cnn: Towards
real-time object detection with region proposal networks)](http://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks)识别感兴趣的候选物体
然后用RNN选择候选物体中的主要物体
将主要物体和之前选中的视角结合通过训练回归器(regressor)来预测如何旋转视角到更好的视角
训练的时候用到了以下函数：
1.用来测量选中视角和标注视角之间距离的回归损失(regression loss)
2.平滑损失(smoothness loss)来使视角转换更加平滑
3.注视到前景物体有额外奖励
使用[策略梯度法(policy gradient technique)](https://link.springer.com/article/10.1007/BF00992696)
先用RCNN检测出物体，再根据[显著性检测器(saliency detector)](https://ieeexplore.ieee.org/abstract/document/7226835)选择最显著的物体
Su(SYC)等人提出了处理360°视频的离线方式[(Pano2Vid)](https://link.springer.com/chapter/10.1007/978-3-319-54190-7_10)，然而这篇文章是在线的基于之前和现在帧观察的像人一样做出反应的代理
只预测方位角和俯仰角
需要人工标注视频作为训练集
###[Learning Spherical Convolution for Fast Features from 360° Imagery](http://papers.nips.cc/paper/6656-learning-spherical-convolution-for-fast-features-from-360-imagery)
<img src="https://i.loli.net/2019/03/26/5c9997cedf2b3.png" alt="1.png" title="1.png" />
背景：
360°图像不变形就不能投影到一个简单的平面上，cnn需要平的图像才能训练
解决方案：
球面卷积网络让平面CNN在它的矩形投影上直接处理360°图像
能从图像和视频中提取足够的特征
传统的在360°图像上应用CNN的方法：
1.用全球投影将360°图像变为一个平面上的图(速度快，不准确)
2.在球面上采样多个区域，将它们分别变为平面投影再独立使用CNN(速度慢，更准确)
任何球到平面的投影都会产生形变
测试用到的数据集：Pano2Vid,PASCAL VOC
缺点：
不能处理非常近的物体
实验：
检测它卷积的准确性和在360°数据中识别物体的适用性(与[VGG](https://github.com/rbgirshick/py-faster-rcnn)和Faster_RCNN对比)
###[Learning to look around: intelligently exploring unseen environments for unknown tasks](http://openaccess.thecvf.com/content_cvpr_2018/html/Jayaraman_Learning_to_Look_CVPR_2018_paper.html)
<img src="https://i.loli.net/2019/03/26/5c9997c9dc715.png" alt="10.png" title="10.png" />
背景：
智能选择好的观察视角是一个挑战
利用识别物体方法选景的代理是没有灵魂的
该代理在新的环境中应该能智能地看新的物体
解决方案：
一个可以自己选择环境中富有信息的视角的代理
一个在全景自然场景和3d物体形状上的递归神经网络
训练时不依赖任何识别任务或特别的语义内容
意义：
在没有见过的环境中该代理也能发挥作用
训练数据无需手动标注
###[SphereNet: Learning Spherical Representations for Detection and Classification in Omnidirectional Images](http://openaccess.thecvf.com/content_ECCV_2018/html/Benjamin_Coors_SphereNet_Learning_Spherical_ECCV_2018_paper.html)
###[A Deep Ranking Model for Spatio-Temporal Highlight Detection From a 360◦ Video](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewPaper/17213)
###[Pano2Vid: Automatic Cinematography for Watching 360∘  Videos](http://vision.cs.utexas.edu/projects/Pano2Vid/)
<img src="https://i.loli.net/2019/03/25/5c98e5807a5a7.png" alt="1.png" title="1.png" />
<img src="https://i.loli.net/2019/03/25/5c98e5807a5ce.png" alt="2.png" title="2.png" />
背景：
记录全景视频很方便，拍摄者不需要决定捕获场景中的哪些内容
对看视频的人来说这就变得具有挑战，不知道看哪，找不到最感兴趣的内容
解决方案：
Pano2Vid，设计算法自动控制全景图中NFOV(normal field-of-view 正常视角)相机的姿势和运动(旋转和缩放)，使用户直接观看该相机生成的内容
使用AUTO CAM算法，不需要人工标注